# local-llms-ollama

This repository contains example code and configuration to run local large language models using Ollama.

## Getting started

1. Install Ollama: https://ollama.com/docs
2. Pull a model:
   ```bash
   ollama pull <model-name>
   ```
3. Run a model:
   ```bash
   ollama run <model-name>
   ```

## Contents

- `examples/` — example scripts and notebooks for interacting with local models
- `docker/` — optional Dockerfiles for reproducible environments

## Contributing

Contributions welcome — open issues or PRs with improvements, examples, or tests.

## License

Specify a license for this repository (e.g. MIT).
